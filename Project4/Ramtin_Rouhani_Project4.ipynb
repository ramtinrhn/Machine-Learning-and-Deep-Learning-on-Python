{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing CNNs for Handwritten Character Recognition on EMNIST with W&B Hyperparameter Sweeps\n",
        "\n",
        "**Abstract:**  \n",
        "This notebook demonstrates a complete deep learning workflow for classifying handwritten characters using the EMNIST Balanced dataset. We define a configurable CNN in PyTorch, train a baseline model, perform automated hyperparameter optimization with W&B, and compare results using accuracy, loss curves, and confusion matrices."
      ],
      "metadata": {
        "id": "WCMvGO9CYzZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSzwteqeYvuh",
        "outputId": "88cbe408-58db-400d-ee30-1a0885f136a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import EMNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "\n",
        "# Device selection\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "\n",
        "We use the EMNIST Balanced dataset (digits + letters).  \n",
        "Steps:\n",
        "- Convert images to tensors and normalize to [-1, 1]\n",
        "- Split training set into train (80%) and validation (20%)\n",
        "- Test set remains separate for evaluation\n"
      ],
      "metadata": {
        "id": "UMe7ZpmpY8eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load EMNIST dataset\n",
        "train_dataset = EMNIST(root='./data', split='balanced', train=True, download=True, transform=transform)\n",
        "test_dataset = EMNIST(root='./data', split='balanced', train=False, download=True, transform=transform)\n",
        "\n",
        "# Train / validation split\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Class labels\n",
        "classes = train_dataset.classes\n",
        "print(f\"Classes: {classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbyJl2MIY_qW",
        "outputId": "f215793c-97f2-4b47-8229-e4ffe136c7f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562M/562M [00:04<00:00, 120MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'd', 'e', 'f', 'g', 'h', 'n', 'q', 'r', 't']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization Utilities\n",
        "\n",
        "- `show_samples()`: visualizes n sample images with their labels\n",
        "- `plot_confusion_matrix()`: visualizes model predictions across classes\n"
      ],
      "metadata": {
        "id": "WCCz9EtaZCFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_samples(dataset, classes, n=6):\n",
        "    fig, axes = plt.subplots(1, n, figsize=(12, 3))\n",
        "    for i in range(n):\n",
        "        img, label = dataset[i]\n",
        "        axes[i].imshow(img.squeeze(), cmap=\"gray\")\n",
        "        axes[i].set_title(classes[label])\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_samples(train_dataset, classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "XG23WREsZDuE",
        "outputId": "191af454-be86-4413-d877-40d45726a49f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model\n",
        "\n",
        "Customizable CNN:\n",
        "- Conv blocks: Conv2d → ReLU → MaxPool2d\n",
        "- Automatic shape inference for fully connected layers\n",
        "- FC layers: Linear → ReLU → Dropout → Linear (num_classes)\n",
        "- Hyperparameters: num_filters, kernel_size, num_layers, dropout\n"
      ],
      "metadata": {
        "id": "susTunbwZF0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=len(classes), num_filters=32, kernel_size=3, num_layers=2, dropout=0.5):\n",
        "        super(CNN, self).__init__()\n",
        "        layers = []\n",
        "        in_channels = 1\n",
        "        for i in range(num_layers):\n",
        "            layers.append(nn.Conv2d(in_channels, num_filters, kernel_size=kernel_size, padding=1))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.MaxPool2d(2, 2))\n",
        "            in_channels = num_filters\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "        # Automatic flattened size\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 1, 28, 28)\n",
        "            conv_out = self.conv(dummy_input)\n",
        "            conv_out_size = conv_out.numel()\n",
        "\n",
        "        self.fc1 = nn.Linear(conv_out_size, 128)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "s7tQzFX6ZGqc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Evaluation Utilities\n",
        "\n",
        "- `train_step()`: trains one epoch\n",
        "- `test_step()`: evaluates model\n",
        "- Returns loss and accuracy (%)\n"
      ],
      "metadata": {
        "id": "87MBXlZ0ZJ1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, criterion, optimizer, dataloader, device=device):\n",
        "    running_loss, correct = 0, 0\n",
        "    model.train()\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    return running_loss / len(dataloader), 100 * correct / len(dataloader.dataset)\n",
        "\n",
        "def test_step(model, criterion, dataloader, device=device):\n",
        "    running_loss, correct = 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            running_loss += criterion(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    return running_loss / len(dataloader), 100 * correct / len(dataloader.dataset)\n",
        "\n",
        "def plot_confusion_matrix(model, dataloader, title=\"Confusion Matrix\"):\n",
        "    y_true, y_pred = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_pred.extend(preds.argmax(1).cpu().numpy())\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "mGcyLMZEZLXm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline CNN Training\n",
        "\n",
        "- Model: 2 conv layers, 32 filters, kernel_size=3, dropout=0.5\n",
        "- Optimizer: Adam, lr=0.001\n",
        "- Train for 5 epochs\n",
        "- Batch size: 64\n"
      ],
      "metadata": {
        "id": "U_uwq0KRZM_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "baseline_train_losses, baseline_val_losses = [], []\n",
        "baseline_train_accs, baseline_val_accs = [], []\n",
        "\n",
        "for epoch in range(5):\n",
        "    train_loss, train_acc = train_step(baseline_model, criterion, optimizer, train_loader)\n",
        "    val_loss, val_acc = test_step(baseline_model, criterion, val_loader)\n",
        "    baseline_train_losses.append(train_loss)\n",
        "    baseline_val_losses.append(val_loss)\n",
        "    baseline_train_accs.append(train_acc)\n",
        "    baseline_val_accs.append(val_acc)\n",
        "    print(f\"[Baseline] Epoch {epoch+1}: Train Acc={train_acc:.2f}%, Val Acc={val_acc:.2f}%\")\n",
        "\n",
        "baseline_test_loss, baseline_test_acc = test_step(baseline_model, criterion, test_loader)\n",
        "print(f\"Baseline Test Accuracy: {baseline_test_acc:.2f}%\")\n",
        "plot_confusion_matrix(baseline_model, test_loader, title=\"Baseline Confusion Matrix\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_4i8d0SZNrU",
        "outputId": "81ce423c-e1b6-48a6-f8a0-979d5e26848c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Baseline] Epoch 1: Train Acc=61.19%, Val Acc=81.87%\n",
            "[Baseline] Epoch 2: Train Acc=74.77%, Val Acc=84.09%\n",
            "[Baseline] Epoch 3: Train Acc=77.39%, Val Acc=84.69%\n",
            "[Baseline] Epoch 4: Train Acc=78.87%, Val Acc=85.63%\n",
            "[Baseline] Epoch 5: Train Acc=80.04%, Val Acc=85.82%\n"
          ]
        }
      ]
    }
  ]
}